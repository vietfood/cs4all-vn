---
layout: distill
permalink: /prml/chapter1/prob_theory/bayes
title: "Bayesian Probabilities"
subtitle: "PRML Chapter 1.2.3"
date: 2025-04-23

future: true
htmlwidgets: true
hidden: false

giscus_comments: true

bibliography: main.bib

previous_section: true
next_section: true

previous_section_url: "/cs4all-vn/prml/chapter1/prob_theory/expectation"
previous_section_name: "Expectations and Covariences"
next_section_url: "/cs4all-vn/prml/chapter1/prob_theory/normal"
next_section_name: "Gaussian Distribution"

authors:
  - name: LÃª Nguyá»…n
    url: "https://lenguyen.vercel.app"

toc:
  - name: Äá»‹nh lÃ½ Bayes
  - name: NhÃ¬n ká»¹ hÆ¡n Ä‘á»‹nh lÃ½ Bayes
  - name: Bayes trong Machine Learning
---

## Äá»‹nh lÃ½ Bayes

Má»™t trong nhá»¯ng Ä‘á»‹nh lÃ½ quan trá»ng nháº¥t cá»§a xÃ¡c suáº¥t chÃ­nh lÃ  Ä‘á»‹nh lÃ½ Bayes (tiáº¿ng anh lÃ  *Bayes' Theorem*). Äá»‹nh lÃ½ Ä‘Æ°á»£c phÃ¡t biá»ƒu nhÆ° sau:

<p markdown=1 class="definition">**Äá»‹nh lÃ½ Bayes**:
Cho $X$ vÃ  $Y$ lÃ  2 biáº¿n cá»‘, khi Ä‘Ã³ xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n $P(Y \mid X)$ lÃ : 
\\[
P(Y \mid X) = \dfrac{P(X \mid Y)P(Y)}{P(X)}
\\]
</p>

Giá» hÃ£y nhÃ¬n tháº­t ká»¹ vÃ o cÃ´ng thá»©c nÃ y, nhÃ¬n nÃ³ Ä‘Æ¡n giáº£n tháº¿ nhÆ°ng chÆ°a cháº¯c Ä‘Ã£ váº­y Ä‘Ã¢u. TrÆ°á»›c khi báº¯t Ä‘áº§u giáº£i thÃ­ch sÃ¢u thÃ¬ cÃ¡c báº¡n hÃ£y Ä‘á»c meme á»Ÿ hÃ¬nh 1.

{% include figure.liquid path="https://pbs.twimg.com/media/CE5r1ZMUkAAMWIC.png" class="img-fluid" caption="HÃ¬nh 1: Meme cho ngÃ y vui (tháº­t ra khÃ´ng hÃ i láº¯m ğŸ¥²) (nguá»“n: xkcd)" %}

á» hÃ¬nh 1, cÃ¢u há»i sáº½ lÃ  "Giá» tui má»›i lá»¥m Ä‘Æ°á»£c cÃ¡i vá» sÃ², xÃ¡c suáº¥t mÃ  tui á»Ÿ gáº§n biá»ƒn lÃ  bao nhiÃªu ?". TrÆ°á»›c khi tráº£ lá»i cÃ¢u há»i, thÃ¬ mÃ¬nh biáº¿t Ä‘Æ°á»£c xÃ¡c suáº¥t mÃ¬nh gáº§n biá»ƒn sáº½ lÃ  $0.05$ (bá»Ÿi vÃ¬ mÃ¬nh lÃªn máº¡ng mÃ¬nh tháº¥y váº­y ğŸ’€). Giá» náº¿u mÃ¬nh á»Ÿ gáº§n biá»ƒn (cháº¯c á»Ÿ biá»ƒn luÃ´n, giÃ³ thá»•i hÃ¹ hÃ¹) thÃ¬ xÃ¡c suáº¥t mÃ  mÃ¬nh lá»¥m cÃ¡i vá» sÃ² sáº½ lÃ  $0.7$, tháº¿ nhÆ°ng giáº£ sá»­ mÃ¬nh khÃ´ng gáº§n biá»ƒn thÃ¬ xÃ¡c suáº¥t mÃ¬nh lá»¥m Ä‘Æ°á»£c vá» sÃ² lÃ  $0.001$ (tháº¥p lÃ  Ä‘Ãºng ğŸ¥², mÃ¬nh thÃªm vÃ o bá»Ÿi vÃ¬ hÃ¬nh khÃ´ng cÃ³).

Giá» mÃ¬nh Ä‘áº·t $A$ lÃ  biáº¿n Ä‘á»ƒ mÃ¬nh biáº¿t á»Ÿ gáº§n biá»ƒn hay khÃ´ng, $A = 1$ lÃ  gáº§n vÃ  $A = 0$ lÃ  khÃ´ng. TÆ°Æ¡ng tá»±, mÃ¬nh Ä‘áº·t $B$ lÃ  biáº¿n Ä‘á»ƒ mÃ¬nh biáº¿t mÃ¬nh cÃ³ lá»¥m vá» khÃ´ng, $B = 0$ lÃ  mÃ¬nh khÃ´ng lá»¥m vá» sÃ² vÃ  $B = 1$ lÃ  mÃ¬nh lá»¥m vá» sÃ². Khi nÃ y mÃ¬nh cÃ³:

$$
\begin{aligned}
P(A = 1) &= 0.05 \\
P(B = 1 \mid A = 1) &= 0.7 \\
P(B = 1 \mid A = 0) &= 0.001
\end{aligned}
$$

Náº¿u Ä‘á»ƒ Ã½, Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i, mÃ¬nh cáº§n tÃ¬m xÃ¡c suáº¥t $P(B = 1 \mid A = 1)$. Náº¿u Ã¡p dá»¥ng Ä‘á»‹nh lÃ½ Bayes, mÃ¬nh sáº½ cÃ³:

$$
P(A = 1 \mid B = 1) = \dfrac{P(B = 1 \mid A = 1)P(A = 1)}{P(B = 1)}
$$

Váº­y mÃ¬nh chá»‰ cÃ²n thiáº¿u xÃ¡c suáº¥t $P(B = 1)$ thÃ´i. Náº¿u Ã¡p dá»¥ng sum rule, ta cÃ³:

$$
\begin{aligned}
P(B = 1) &= P(B = 1, A = 0) + P(B = 1, A = 1) \\
&= P(B = 1 \mid A = 0)P(A = 0) + P(B = 1 \mid A = 1)P(A = 1) \\
&= 0.001 \cdot (1 - 0.05) + 0.7 \cdot 0.05 \\
&= 0.03595
\end{aligned}
$$

Giá» Ä‘Ã£ cÃ³ Ä‘á»§, Ã¡p dá»¥ng Bayes thÃ´i:

$$
\begin{aligned}
P(A = 1 \mid B = 1) &= \dfrac{P(B = 1 \mid A = 1)P(A = 1)}{P(B = 1)} \\
&= \dfrac{0.7 \cdot 0.05}{0.03595} \\
&\approx 0.97
\end{aligned}
$$

Váº­y lÃ  náº¿u mÃ¬nh nháº·t Ä‘Æ°á»£c má»™t vá» sÃ² thÃ¬ cÃ³ Ä‘áº¿n $97\%$ mÃ¬nh á»Ÿ gáº§n biá»ƒn ğŸ˜², máº·c dÃ¹ xÃ¡c suáº¥t má»—i cÃ¡i nhÃ¬n ráº¥t Ã­t, nhÆ°ng khi dÃ¹ng Bayes láº¡i cho xÃ¡c suáº¥t ráº¥t cao.

## NhÃ¬n ká»¹ hÆ¡n Ä‘á»‹nh lÃ½ Bayes

Giá» náº¿u ta xem, xÃ¡c suáº¥t vá» má»™t biáº¿n cá»‘ nÃ o Ä‘Ã³ chÃ­nh lÃ  thÃ´ng tin vá» biáº¿n cá»‘ Ä‘Ã³. VÃ­ dá»¥ $P(\text{tá»‘i nay báº¡n Ä‘i ngá»§}) = 0.7$ thÃ¬ mÃ¬nh biáº¿t lÃ  tá»‘i nay, cÃ³ $70\%$ kháº£ nÄƒng lÃ  báº¡n sáº½ Ä‘i ngá»§ vÃ  Ä‘Ã¢y lÃ  thÃ´ng tin mÃ¬nh cÃ³ vá» viá»‡c báº¡n Ä‘i ngá»§ tá»‘i nay.

Náº¿u nhÃ¬n vÃ o cÃ´ng thá»©c Bayes, ngÆ°á»i ta cÃ³ quy Ä‘á»‹nh vá» tÃªn gá»i cá»§a tá»«ng xÃ¡c suáº¥t cÃ³ máº·t trong cÃ´ng thá»©c Ä‘Ã³. Äáº§u tiÃªn lÃ  $P(Y)$ sáº½ Ä‘Æ°á»£c gá»i lÃ  **prior probability** (hay *xÃ¡c suáº¥t tiÃªn nghiá»‡m*), sá»Ÿ dÄ© gá»i váº­y lÃ  vÃ¬ Ä‘Ã¢y lÃ  *thÃ´ng tin* Ä‘áº§u tiÃªn mÃ  ta cÃ³ khi nÃ³i vá» biáº¿n cá»‘ $Y$. Thay vÃ¬ hiá»ƒu $P(Y)$ lÃ  xÃ¡c suáº¥t $Y$ sáº½ xáº£y ra nhÆ° cÃ¡ch thÃ´ng thÆ°á»ng, theo Bayes (hay trÆ°á»ng phÃ¡i Bayes, gá»i lÃ  Bayesian) thÃ¬ $P(Y)$ lÃ  **degree of belief** (hay má»©c Ä‘á»™ niá»m tin) mÃ  ta tin ráº±ng $Y$ sáº½ xáº£y ra, $P(Y)$ cÃ ng cao thÃ¬ ta cÃ ng tá»± tin vÃ o suy nghÄ© cá»§a mÃ¬nh hÆ¡n. 

Tháº¿ nÃªn theo Bayesian, xÃ¡c suáº¥t mang tÃ­nh *chá»§ quan* hÆ¡n, vÃ­ dá»¥ báº¡n An á»Ÿ Má»¹, nÃªn báº¡n An chÆ°a bao giá» Äƒn bÃºn Ä‘áº­u máº¯m tÃ´m do Ä‘Ã³ $P(\text{bÃºn Ä‘áº­u ngon})$ cá»§a báº¡n An ráº¥t tháº¥p, cÃ²n mÃ¬nh má»—i tuáº§n Äƒn 1 láº§n nÃªn $P(\text{bÃºn Ä‘áº­u ngon})$ cá»§a mÃ¬nh ráº¥t cao (ngon tháº­t). CÃ¹ng má»™t biáº¿n cá»‘ nhÆ°ng láº¡i cÃ³ xÃ¡c suáº¥t khÃ¡c nhau, nhÆ°ng viá»‡c nÃ y do Ä‘Ã¢u nhá»‰ ?

Giá» giáº£ sá»­, báº¡n An Äƒn bÃºn Ä‘áº­u láº§n Ä‘áº§u, khi Ä‘Ã³ vá»›i thÃ´ng tin má»›i báº¡n An cÃ³ lÃ  $P(\text{Ä‘Ã£ Äƒn bÃºn Ä‘áº­u})$, niá»m tin cá»§a báº¡n An Ä‘Æ°á»£c gia tÄƒng (hoáº·c giáº£m xuá»‘ng) bá»Ÿi vÃ¬ $P(\text{bÃºn Ä‘áº­u ngon})$ giá» Ä‘Ã£ trá»Ÿ thÃ nh $P(\text{bÃºn Ä‘áº­u ngon} \mid \text{Ä‘Ã£ Äƒn bÃºn Ä‘áº­u})$. Ta gá»i cÃ¡i nÃ y kiá»ƒu nhÆ° **update** niá»m tin cá»§a mÃ¬nh váº­y, mÃ¬nh sáº½ cÃ³ má»™t niá»m tin ban Ä‘áº§u, khi nhÃ¬n tháº¥y má»™t cÃ¡i gÃ¬ Ä‘Ã³ má»›i, mÃ¬nh sáº½ update cÃ¡i niá»m tin cá»§a mÃ¬nh vÃ  update báº±ng cÃ´ng thá»©c Bayes. Váº­y do mÃ¬nh Ä‘Ã£ Äƒn bÃºn Ä‘áº­u ráº¥t nhiá»u láº§n nÃªn $P(\text{bÃºn Ä‘áº­u ngon})$ cá»§a mÃ¬nh cao lÃ  Ä‘Æ°Æ¡ng nhiÃªn (mÃ¬nh Ä‘Ã£ update nhiá»u láº§n rá»“i, má»—i láº§n Äƒn ngon nÃªn update nhÃ©).

Háº¿t vÃ­ dá»¥ thÃ¬ ta Ä‘Ã£ rÃµ hÆ¡n Bayesian chÃºt rá»“i. Ta gá»i $P(Y \mid X)$ lÃ  **posterior probability** (hay *xÃ¡c suáº¥t háº­u nghiá»‡m*) bá»Ÿi vÃ¬ Ä‘Ã¢y lÃ  niá»m tin ta cÃ³ sau khi quan sÃ¡t Ä‘Æ°á»£c má»™t thÃ´ng tin má»›i xáº£y ra, á»Ÿ Ä‘Ã¢y lÃ  $P(X)$, ngoÃ i ra $P(X)$ Ä‘Æ°á»£c gá»i lÃ  **evidence**. CÃ²n láº¡i lÃ  $P(X \mid Y)$, xÃ¡c suáº¥t nÃ y Ä‘Æ°á»£c ta gá»i lÃ  **likelihood**, nÃ y thÃ¬ khÃ¡ khÃ³ giáº£i thÃ­ch (nhÆ°ng mÃ  ráº¥t quan trá»ng Ä‘Ã³) nÃªn mÃ¬nh Ä‘á»ƒ cÃ¡c Ä‘á»™c giáº£ tá»± giáº£i thÃ­ch ğŸ˜­.

## Bayes trong Machine Learning 

Äá»‹nh lÃ½ Bayes cÅ©ng cÃ³ thá»ƒ Ã¡p dá»¥ng trong Machine Leanring nhÆ° sau. Giáº£ sá»­ ráº±ng ta cÃ³ táº­p dá»¯ liá»‡u $\mathcal{D}$ vÃ  má»™t model cÃ³ bá»™ tham sá»‘ lÃ  $\mathbf{w}$. Má»¥c Ä‘Ã­ch cá»§a ta lÃ  vá»›i táº­p dá»¯ liá»‡u $\mathcal{D}$ nhÆ° nÃ y, bá»™ tham sá»‘ $\mathbf{w}$ cá»§a ta nhÆ° nÃ o má»›i lÃ  tá»‘t, tá»©c lÃ  tÃ¬m xÃ¡c suáº¥t $p(\mathbf{w} \mid \mathcal{D})$.

Giáº£ sá»­ ta Ä‘Ã£ chá»n Ä‘Æ°á»£c má»™t mÃ´ hÃ¬nh vá»›i bá»™ tham sá»‘ $\mathbf{w}$. TrÆ°á»›c khi cÃ³ táº­p dá»¯ liá»‡u $\mathcal{D}$, ta ngáº§m giáº£ Ä‘á»‹nh ráº±ng $\mathbf{w}$ cÃ³ phÃ¢n phá»‘i lÃ  $p(\mathbf{w})$. Sá»­ dá»¥ng Ä‘á»‹nh lÃ½ Bayes, ta cÃ³:
$$
p(\mathbf{w} \mid \mathcal{D}) = \frac{p(\mathcal{D} \mid \mathbf{w})p(\mathbf{w})}{p(\mathcal{D})}
$$
PhÃ¢n phá»‘i $p(\mathcal{D} \mid \mathbf{w})$ á»Ÿ bÃªn pháº£i cá»§a Ä‘á»‹nh lÃ½ Bayes lÃ  má»™t hÃ m phá»¥ thuá»™c vÃ o $\mathcal{D}$, tháº¿ nhÆ°ng náº¿u ta xem phÃ¢n phá»‘i áº¥y lÃ  má»™t hÃ m phá»¥ thuá»™c vÃ o $\mathbf{w}$, thÃ¬ khi Ä‘Ã³ ta gá»i $p(\mathcal{D} \mid \mathbf{w})$ lÃ  **hÃ m likelihood** (likelihood function).

<p markdown=1 class="takeaway">
Thay vÃ¬ viáº¿t $p(\mathcal{D} \mid \mathbf{w})$ Ä‘á»ƒ dá»… bá»‹ nháº§m láº«n giá»¯a phÃ¢n phá»‘i xÃ¡c suáº¥t vÃ  hÃ m likelihood, ta sáº½ kÃ­ hiá»‡u:

\\[
\mathcal{L}(\mathbf{w} \mid \mathcal{D}) = p(\mathcal{D} \mid \mathbf{w})
\\]

trong Ä‘Ã³ $\mathcal{L}(\mathbf{w} \mid \mathcal{D})$ lÃ  hÃ m likelihood cÃ³ biáº¿n lÃ  $\mathbf{w}$ cÃ²n $p(\mathcal{D} \mid \mathbf{w})$ lÃ  phÃ¢n phá»‘i cÃ³ biáº¿n lÃ  $\mathcal{D}$.
</p>

Dá»±a vÃ o Ä‘á»‹nh nghÄ©a cá»§a likelihood, ta cÃ³ thá»ƒ viáº¿t láº¡i Ä‘á»‹nh lÃ½ Bayes nhÆ° sau:

$$
\text{posterior} \propto \text{likelihood} \times \text{prior}
$$

trong Ä‘Ã³ $\text{likelihood}, \text{posterior}$ vÃ  $\text{prior}$ Ä‘á»u lÃ  cÃ¡c hÃ m phá»¥ thuá»™c vÃ o $\mathbf{w}$. CÃ²n giÃ¡ trá»‹ $p(\mathcal{D})$ dÆ°á»›i máº«u lÃ  má»™t háº±ng sá»‘, dÃ¹ng Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng phÃ¢n phá»‘i háº­u nghiá»‡m á»Ÿ bÃªn pháº£i Ä‘á»‹nh lÃ½ Bayes Ä‘Ãºng lÃ  má»™t phÃ¢n phá»‘i (máº­t Ä‘á»™ xÃ¡c suáº¥t).

<p markdown=1 class="takeaway">
KÃ­ hiá»‡u $\propto$ nghÄ©a lÃ  tá»‰ lá»‡. VÃ­ dá»¥, chiá»u cao ($h$) $= 1.2 \times$ cÃ¢n náº·ng ($w$), lÃºc nÃ y ta nÃ³i chiá»u cao tá»‰ lá»‡ vá»›i cÃ¢n náº·ng hay $h \propto w$. á» Ä‘á»‹nh lÃ½ Bayes, náº¿u ta xem $1 / p(\mathcal{D})$ lÃ  má»™t háº±ng sá»‘ (mÃ  nÃ³ lÃ  má»™t háº±ng sá»‘ tháº­t, bá»Ÿi vÃ¬ $\mathcal{D}$ khÃ´ng Ä‘á»•i rá»“i) thÃ¬ $p(\mathbf{w} \mid \mathcal{D}) \propto \mathcal{L}(\mathbf{w} \mid \mathcal{D})p(\mathbf{w})$.
</p>

Ãp dá»¥ng sum rule vÃ  product rule ([Probability Densities](/cs4all-vn/prml/chapter1/prob_theory/density)) cho biáº¿n tá»¥c, ta cÃ³:

$$
p(\mathcal{D}) = \int p(\mathcal{D} \mid \mathbf{w}) p(\mathbf{w}) d\mathbf{w}
$$

Váº­y:

$$
\begin{aligned}
\int_{-\infty}^{\infty} p(\mathbf{w} \mid \mathcal{D}) d\mathbf{w} &= \int_{-\infty}^{\infty} \frac{p(\mathcal{D} \mid \mathbf{w})p(\mathbf{w})}{p(\mathcal{D})} d\mathbf{w} \\
&= \frac{\int p(\mathcal{D}\mid \mathbf{w})p(\mathbf{w}) d\mathbf{w}}{\int p(\mathcal{D}\mid \mathbf{w})p(\mathbf{w}) d\mathbf{w}} = 1
\end{aligned}
$$

CÃ²n viá»‡c $p(\mathbf{w} \mid \mathcal{D}) \geq 0$ mÃ¬nh nghÄ© khÃ¡ lÃ  dá»… tháº¥y rá»“i.

Váº­y sinh ra cÃ¡i Bayes nÃ y lÃ m gÃ¬, má»¥c Ä‘Ã­ch cá»§a chÃºng ta Ä‘Ã³ lÃ  cá»‘ gáº¯ng tÃ¬m bá»™ tham sá»‘ $\mathbf{w}$ sao cho $p(\mathbf{w} \mid \mathcal{D})$ lÃ  tá»‘t nháº¥t, kiá»ƒu nhÆ° ta Ä‘Ã£ biáº¿t trÆ°á»›c táº­p dá»¯ liá»‡u $\mathcal{D}$ (tá»©c lÃ  ta Ä‘Ã£ biáº¿t trÆ°á»›c káº¿t quáº£ rá»“i), ta cáº§n tÃ¬m mÃ´ hÃ¬nh (tham sá»‘ $\mathbf{w}$) phÃ¹ há»£p vá»›i $\mathcal{D}$ nháº¥t (tá»©c lÃ  ta Ä‘i tÃ¬m nguyÃªn nhÃ¢n cho ra káº¿t quáº£ vÃ  nguyÃªn nhÃ¢n Ä‘Ã³ pháº£i lÃ  phÃ¹ há»£p vá»›i káº¿t quáº£ nháº¥t, váº­y lÃ  tÃ¬m xÃ¡c suáº¥t $p(\mathbf{w}\mid \mathcal{D})$ lá»›n nháº¥t) (mÃ¬nh copy cÃ¡ch giáº£i thÃ­ch nÃ y tá»« <d-footnote>Machine Learning cÆ¡ báº£n - BÃ i 31 (https://machinelearningcoban.com/2017/07/17/mlemap/)</d-footnote>.

<p markdown=1 class="takeaway">
NgoÃ i cÃ¡ch giáº£i thÃ­ch trÃªn, ta hÃ£y xem xÃ¡c suáº¥t nhÆ° *má»©c Ä‘á»™ cá»§a niá»m tin* (degree of belief) tá»©c lÃ  xÃ¡c suáº¥t cÃ ng cao, ta cÃ ng tin lÃ  nÃ³ sáº½ tá»‘t (hoáº·c sáº½ xáº£y ra). TrÆ°á»›c khi cÃ³ data quan sÃ¡t Ä‘Æ°á»£c dá»¯ liá»‡u $\mathcal{D}$, ta tin ráº±ng $\mathbf{w}$ sáº½ tá»‘t (lÃ  má»™t mÃ´ hÃ¬nh phÃ¹ há»£p vá»›i $\mathcal{D}$) á»Ÿ má»™t má»©c Ä‘á»™ nÃ o Ä‘Ã³, tá»©c lÃ  $p(\mathbf{w})$, sau khi quan sÃ¡t Ä‘Æ°á»£c dá»¯ liá»‡u ${} \mathcal{D}$ rá»“i, niá»m tin vá» Ä‘á»™ phÃ¹ há»£p cá»§a $\mathbf{w}$ vá»›i ${} \mathcal{D} {}$ sáº½ thay Ä‘á»•i vÃ  cÃ³ giÃ¡ trá»‹ lÃ  $p(\mathbf{w} \mid \mathcal{D})$ 
</p>

Äá»‘i vá»›i frequentist thÃ¬ ta sáº½ dÃ¹ng phÆ°Æ¡ng phÃ¡p **maximum likelihood** (MLE) Ä‘á»ƒ tÃ¬m giÃ¡ trá»‹ $p(\mathcal{D} \mid \mathbf{w})$ lá»›n nháº¥t tá»« Ä‘Ã³ tÃ¬m Ä‘Æ°á»£c $p(\mathbf{w} \mid \mathcal{D})$ lá»›n nháº¥t (frequentist giáº£ sá»­ ráº±ng $p(\mathbf{w})$ vÃ  $p(\mathcal{D})$ lÃ  cÃ¡c háº±ng sá»‘, á»Ÿ gÃ³c nhÃ¬n cá»§a frequentist, ta sáº½ xem $\mathbf{w}$ nhÆ° lÃ  má»™t giÃ¡ trá»‹ mÃ  ta Æ°á»›c lÆ°á»£ng Ä‘Æ°á»£c, do Ä‘Ã³ $p(\mathbf{w})$ lÃ  má»™t háº±ng sá»‘) Ta sáº½ tÃ¬m hiá»ƒu phÆ°Æ¡ng phÃ¡p nÃ y á»Ÿ pháº§n [Gaussian Distribution](/cs4all-vn/prml/chapter1/prob_theory/normal).

CÃ²n Ä‘á»‘i vá»›i bayesian, ta cÃ³ phÆ°Æ¡ng phÃ¡p gá»i lÃ  **maximum a posteriori estimation** (MAP). Bayesian cho ráº±ng $\mathbf{w}$ lÃ  má»™t biáº¿n ngáº«u nhiÃªn chá»© khÃ´ng pháº£i má»™t giÃ¡ trá»‹, do Ä‘Ã³ $p(\mathbf{w})$ lÃ  má»™t phÃ¢n phá»‘i. Váº­y Ä‘á»ƒ tÃ¬m Ä‘Æ°á»£c $p(\mathbf{w} \mid \mathcal{D})$ lá»›n nháº¥t ta pháº£i tÃ¬m cáº£ likelihood $p(\mathcal{D} \mid \mathbf{w})$ vÃ  prior $\mathcal{p}(\mathbf{w})$.